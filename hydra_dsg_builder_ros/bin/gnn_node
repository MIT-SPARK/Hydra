#!/usr/bin/env python3
"""Run inference on received scene graphs."""
import spark_dsg as dsg
import pandas as pd
import numpy as np
import torch_geometric
import gensim.models
import pathlib
import logging
import pickle
import torch
import click
import heapq
import yaml


DEFAULT_LAYERS = (dsg.DsgLayers.OBJECTS, dsg.DsgLayers.ROOMS, dsg.DsgLayers.BUILDINGS)


def _is_on(G, n1, n2, threshold_on=1.0):
    """
    Check whether n1 is "on" n2 or n2 is "on" n1

    Requires that the n1 center is inside n2 on xy plane, and n1 is above
    n2 on z-axis within a threshold (or vice-versa).
    """
    pos1 = G.get_position(n1.id.value)
    pos2 = G.get_position(n2.id.value)
    size1 = _get_size(n1)
    size2 = _get_size(n2)

    xy_dist = np.abs(pos1[0:2] - pos2[0:2])
    z_dist = np.abs(pos1[2] - pos2[2])
    n1_above_n2 = pos1[2] > pos2[2]
    new_thresh = threshold_on * (size1[2] + size2[2]) / 2

    if all(xy_dist <= size2[0:2] / 2) and n1_above_n2 and z_dist <= new_thresh:
        return True
    elif all(xy_dist <= size1[0:2] / 2) and not n1_above_n2 and z_dist <= new_thresh:
        return True
    else:
        return False


def _is_above(G, n1, n2, threshold_near=2.0, threshold_on=1.0):
    """
    Check whether n1 is "above" n2 or n2 is "above" n1

    Requires that the n1 center and n2 are nearby on the xy plane, and n1 is above
    n2 on z-axis by an amount greater than a provided threshold.
    """
    pos1 = G.get_position(n1.id.value)
    pos2 = G.get_position(n2.id.value)
    size1 = _get_size(n1)
    size2 = _get_size(n2)
    near_thresh = (size1[0:2] + size2[0:2]) / 2.0 * threshold_near

    xy_dist = np.abs(pos1[0:2] - pos2[0:2])
    z_dist = np.abs(pos1[2] - pos2[2])
    n1_above_n2 = pos1[2] > pos2[2]
    dist_thresh = threshold_on * (size1[2] + size2[2]) / 2

    if all(xy_dist <= near_thresh):
        if n1_above_n2 and z_dist > dist_thresh:
            return True
        if not n1_above_n2 and z_dist > dist_thresh:
            return True

    return False


def _is_under(G, n1, n2):
    """
    Check whether n1 is "under" n2 or n2 is "under" n1

    Requires that either n1 or n2 is inside the other node on the xy place and
    that the positions on the z-axis are distinct.
    """
    pos1 = G.get_position(n1.id.value)
    pos2 = G.get_position(n2.id.value)
    size1 = _get_size(n1)
    size2 = _get_size(n2)

    xy_dist = np.abs(pos1[0:2] - pos2[0:2])

    if all(xy_dist <= size1[0:2] / 2) or all(xy_dist <= size2[0:2] / 2):
        if pos1[2] < pos2[2]:
            return True
        if pos2[2] < pos1[2]:
            return True

    return False


def _is_near(G, n1, n2, threshold_near=2.0, max_near=2.0):
    """
    Check whether n1 is "near" n2 or n2 is "near" n1

    Requires that either n1 or n2 is inside the other node on the xy place and
    that the positions on the z-axis are distinct.
    """
    pos1 = G.get_position(n1.id.value)
    pos2 = G.get_position(n2.id.value)
    size1 = _get_size(n1)
    size2 = _get_size(n2)

    avg_size = (size1 + size2) / 2.0
    near_thresh = avg_size * threshold_near

    dist = np.abs(pos1 - pos2)

    # [LocatedNear]
    if all(dist <= near_thresh) and all(dist - avg_size <= max_near * np.ones(3)):
        return True

    return False


def _load_word2vec(model_file):
    return gensim.models.KeyedVectors.load_word2vec_format(model_file, binary=True)


def _get_embedding(model, label, dim=300):
    vec = np.zeros(dim)
    try:
        vec = np.mean(
            [model[s] for s in label.split("_") if s != "of"],
            axis=0,
        )
    except KeyError:
        print(f"{label} cannot be found in pretrained word2vec")

    return torch.from_numpy(vec.astype(np.float32))


def _get_room_labels(room_file):
    room_df = pd.read_csv(
        room_file, usecols=range(2), names=["char", "room_name"], header=None
    )
    return sorted(list(set(room_df["room_name"].to_list())))


def _get_size(node):
    return node.attributes.bounding_box.max - node.attributes.bounding_box.min


def _dist(G, n1, n2):
    return np.linalg.norm(G.get_position(n1) - G.get_position(n2))


def _get_node_masks_and_features(
    G, embeddings, layers=DEFAULT_LAYERS, embedding_size=300
):
    num_infer_nodes = sum([G.get_layer(x).num_nodes() for x in layers])
    masks = {x: torch.zeros(num_infer_nodes, dtype=torch.bool) for x in layers}

    features = []
    id_map = {}
    ids = []
    for node in G.nodes:
        if node.layer not in layers:
            continue

        # len is a proxy for index
        masks[node.layer][len(features)] = True
        id_map[node.id.value] = len(features)
        ids.append(node.id.value)

        label = node.attributes.semantic_label
        if node.id.category == "O":
            embedding = embeddings.get(label, np.zeros(embedding_size))
        else:
            embedding = np.zeros(embedding_size)
        pos = node.attributes.position
        size = _get_size(node)
        features.append(np.hstack((pos, size, embedding)))

    id_tensor = torch.tensor(np.array([ids]).T)
    return (
        masks,
        id_map,
        id_tensor,
        torch.tensor(np.array(features), dtype=torch.float32),
    )


def _get_layer_edge_index(masks, edge_idx, l1, l2=None, undirected=False):
    edge_mask = (
        masks[l1][edge_idx].all(0)
        if l2 is None
        else masks[l1][edge_idx[0, :]] & masks[l2][edge_idx[1, :]]
    )

    layer_idx = edge_idx[:, edge_mask]
    if not undirected:
        return layer_idx

    if edge_mask.any().item():
        return torch_geometric.utils.to_undirected(layer_idx)
    else:
        return layer_idx


def _add_edge_attr(data):
    edge_index = torch.cat(
        (
            data.object_edge_index,
            data.room_edge_index,
            data.object_room_edge_index,
            data.room_building_edge_index,
            torch.flipud(data.room_building_edge_index),
            torch.flipud(data.object_room_edge_index),
        ),
        1,
    )
    edge_attr_list = [
        torch.tensor([[1, 0, 0, 0, 0, 0]]),
        torch.tensor([[0, 1, 0, 0, 0, 0]]),
        torch.tensor([[0, 0, 1, 0, 0, 0]]),
        torch.tensor([[0, 0, 0, 1, 0, 0]]),
        torch.tensor([[0, 0, 0, 0, 1, 0]]),
        torch.tensor([[0, 0, 0, 0, 0, 1]]),
    ]
    edge_attr = torch.cat(
        [edge_attr_list[0]] * data.object_edge_index.shape[1]
        + [edge_attr_list[1]] * data.room_edge_index.shape[1]
        + [edge_attr_list[2]] * data.object_room_edge_index.shape[1]
        + [edge_attr_list[3]] * data.room_building_edge_index.shape[1]
        + [edge_attr_list[4]] * data.room_building_edge_index.shape[1]
        + [edge_attr_list[5]] * data.object_room_edge_index.shape[1],
        0,
    ).type(torch.float32)
    data.edge_index = edge_index
    data.edge_attr = edge_attr


def _get_room_parent(node, prefix="R"):
    for parent in node.parents():
        if dsg.NodeSymbol(parent).category == prefix:
            return parent

    return None


def _add_object_connectivity(G, threshold_near=2.0, threshold_on=1.0, max_near=2.0):
    room_to_objects = dict()
    for node in G.get_layer(dsg.DsgLayers.OBJECTS).nodes:
        room_id = _get_room_parent(node)
        if room_id is None:
            print(f"skipping invalid object {node.id}")
            continue

        if room_id not in room_to_objects:
            room_to_objects[room_id] = [node]
            continue

        cmp_nodes = room_to_objects[room_id]
        for cmp_node in cmp_nodes:
            is_on = _is_on(G, node, cmp_node, threshold_on=threshold_on)
            is_above = _is_above(
                G,
                node,
                cmp_node,
                threshold_near=threshold_near,
                threshold_on=threshold_on,
            )
            is_under = _is_under(G, node, cmp_node)
            is_near = _is_near(
                G, node, cmp_node, threshold_near=threshold_near, max_near=max_near
            )

            if is_on or is_above or is_under or is_near:
                # TODO(nathan) consider getting direction
                assert G.insert_edge(node.id.value, cmp_node.id.value)

        room_to_objects[room_id].append(node)


def _get_parent_of_closest_neighbor(G, x, max_hop=1):
    frontier = [(_dist(G, x.id.value, n), n) for n in x.siblings()]
    heapq.heapify(frontier)

    visited = set([x.id.value])

    while len(frontier) != 0:
        dist, curr_id = heapq.heappop(frontier)
        visited.add(curr_id)
        curr = G.get_node(curr_id)

        curr_parent = curr.get_parent()
        if curr_parent is not None:
            return curr_parent

        for s in curr.siblings():
            if s in visited:
                continue

            heapq.heappush(frontier, (_dist(G, x.id.value, s), s))

    return None


def _show_info(node):
    print(f"node: {node.id}")
    print(f"  - siblings: {[dsg.NodeSymbol(x) for x in node.siblings()]}")
    print(f"  - parents: {[dsg.NodeSymbol(x) for x in node.parents()]}")
    print(f"  - children: {[dsg.NodeSymbol(x) for x in node.children()]}")


def _get_object_room(G, node):
    place_id = node.get_parent()
    if place_id is not None:
        place = G.get_node(place_id)
        place_parent = place.get_parent()
        if place_parent is not None:
            return place_parent

        closest_place_parent = _get_parent_of_closest_neighbor(G, place)
        if closest_place_parent is not None:
            return closest_place_parent

    node_pos = G.get_position(node.id.value)
    candidate_rooms = [
        x
        for x in G.get_layer(dsg.DsgLayers.ROOMS).nodes
        if x.attributes.bounding_box.is_inside(node_pos)
    ]
    if len(candidate_rooms) == 0:
        return None

    # TODO(nathan) we should probably pick the closest, but...
    return candidate_rooms[0].id.value


def preprocess_dsg(G, threshold_near=2.0, threshold_on=1.0, max_near=2.0):
    dsg.add_bounding_boxes_to_layer(G, dsg.DsgLayers.ROOMS)
    dsg.add_bounding_boxes_to_layer(G, dsg.DsgLayers.BUILDINGS)

    objects = G.get_layer(dsg.DsgLayers.OBJECTS)
    invalid_objects = []
    for node in objects.nodes:
        room_id = _get_object_room(G, node)
        if room_id is None:
            num_parents = len(node.parents())
            print(f"failed to find parent for {node.id} ({num_parents} parents)")
            invalid_objects.append(node.id.value)
            continue

        assert G.insert_edge(node.id.value, room_id)

    for object_id in invalid_objects:
        G.remove_node(object_id)

    _add_object_connectivity(
        G, threshold_near=threshold_near, max_near=max_near, threshold_on=threshold_on
    )


def convert_to_torch_data(G, embedding_dict, add_edge_attr=False):
    """Convert a graph to a pytorch tensor."""
    # this automatically maps all rooms and buildings to unknown (zero) embeddings
    masks, id_map, id_tensor, x = _get_node_masks_and_features(G, embedding_dict)

    # fill edge_index
    edge_index = []
    for edge in G.edges:
        if edge.source not in id_map or edge.target not in id_map:
            continue

        source_node = G.get_node(edge.source)
        target_node = G.get_node(edge.target)
        if source_node.layer > target_node.layer:
            edge_index.append([id_map[edge.target], id_map[edge.source]])
        else:
            edge_index.append([id_map[edge.source], id_map[edge.target]])

    edge_index = torch.tensor(edge_index, dtype=torch.long).T

    # TODO(nathan) make this more generic / check how sgl uses data fields
    R_edges = _get_layer_edge_index(
        masks, edge_index, dsg.DsgLayers.ROOMS, undirected=True
    )
    O_edges = _get_layer_edge_index(
        masks, edge_index, dsg.DsgLayers.OBJECTS, undirected=True
    )

    RB_edges = _get_layer_edge_index(
        masks, edge_index, dsg.DsgLayers.ROOMS, dsg.DsgLayers.BUILDINGS
    )
    OR_edges = _get_layer_edge_index(
        masks, edge_index, dsg.DsgLayers.OBJECTS, dsg.DsgLayers.ROOMS
    )

    torch_data = torch_geometric.data.Data(
        x=x,
        object_mask=masks[dsg.DsgLayers.OBJECTS],
        room_mask=masks[dsg.DsgLayers.ROOMS],
        building_mask=masks[dsg.DsgLayers.BUILDINGS],
        room_edge_index=R_edges,
        object_edge_index=O_edges,
        room_building_edge_index=RB_edges,
        object_room_edge_index=OR_edges,
        edge_index=torch.cat((RB_edges, OR_edges, R_edges, O_edges), dim=1),
    )

    room_ids = id_tensor[masks[dsg.DsgLayers.ROOMS]]
    room_ids = [dsg.NodeSymbol(x[0]) for x in room_ids.tolist()]
    room_idx_map = {x: idx for idx, x in enumerate(room_ids)}

    if add_edge_attr:
        _add_edge_attr(torch_data)

    return torch_data, room_idx_map


class GnnModel:
    """Class to hold stuff regarding inference."""

    def __init__(self, model_file, word2vec_file, config_file, load_word2vec=True):
        """Load everything."""
        model_path = pathlib.Path(model_file).expanduser().absolute()
        with model_path.open("rb") as fin:
            self.model = pickle.load(fin)

        word2vec_path = pathlib.Path(word2vec_file).expanduser().absolute()
        if load_word2vec:
            word2vec = _load_word2vec(word2vec_path)
        else:
            word2vec = {}

        config_path = pathlib.Path(config_file).expanduser().absolute()
        with config_path.open("r") as fin:
            self.config = yaml.load(fin.read(), Loader=yaml.SafeLoader)

        self.object_labels = [x for _, x in self.config["object_labels"].items()]
        self.object_embeddings = {
            idx: _get_embedding(word2vec, label)
            for idx, label in enumerate(self.object_labels)
        }

        self.building_labels = sorted(self.config["building_labels"])
        self.room_labels = sorted(self.config["room_labels"])

        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)

    def infer(self, G, run_inference=True):
        preprocess_dsg(G)
        if run_inference:
            torch_graph, room_idx_map = convert_to_torch_data(
                G, self.object_embeddings, add_edge_attr=True
            )

            with torch.no_grad():
                pred = self.model(torch_graph.to(self.device))
                building_pred = pred[0].argmax(dim=1).cpu()
                room_pred = pred[1].argmax(dim=1).cpu()
                if len(building_pred) == 1:
                    building_name = self.building_labels[building_pred[0]]
                    print(f"building: {building_name}")
                pred_room_labels = [self.room_labels[x] for x in room_pred]
                pred_room_map = {
                    room: pred_room_labels[idx] for room, idx in room_idx_map.items()
                }
                print(f"rooms: {pred_room_map}")
                return pred_room_map

        return None


@click.group()
def main():
    pass


@main.command()
@click.argument("network")
@click.argument("word2vec-file")
@click.argument("config")
@click.option("--recv-url", "-r", default="tcp://127.0.0.1:8001")
@click.option("--send-url", "-s", default="tcp://127.0.0.1:8002")
@click.option("--num-threads", "-t", default=2)
@click.option("--poll-time-ms", default=10)
def run(network, word2vec_file, config, recv_url, send_url, num_threads, poll_time_ms):
    """Run everything."""
    logging.basicConfig(
        format="[%(asctime)s %(levelname)s] %(message)s", level=logging.DEBUG
    )

    model = GnnModel(network, word2vec_file, config)

    logging.info(f"setting up sender @ {send_url}")
    sender = dsg.DsgSender(send_url)

    logging.info(f"setting up receiver @ {recv_url}")
    receiver = dsg.DsgReceiver(recv_url)

    while True:
        if not receiver.recv(poll_time_ms):
            continue

        logging.info(f"curr nodes: {receiver.graph.num_nodes(False)}")
        pred_room_map = model.infer(receiver.graph)

        G = dsg.DynamicSceneGraph()
        for room_id, label in pred_room_map.items():
            attrs = dsg.RoomNodeAttributes()
            attrs.name = f"{room_id}: {label}"
            G.add_node(dsg.DsgLayers.ROOMS, room_id.value, attrs)

        sender.send(G)


@main.command()
@click.argument("network")
@click.argument("word2vec-file")
@click.argument("config")
@click.argument("dsg_file")
def test(network, word2vec_file, config, dsg_file):
    """Run everything."""
    logging.basicConfig(
        format="[%(asctime)s %(levelname)s] %(message)s", level=logging.DEBUG
    )

    model = GnnModel(network, word2vec_file, config)

    dsg_path = pathlib.Path(dsg_file).expanduser().absolute()
    logging.info(f"loading scene graph from {dsg_path}")
    G = dsg.DynamicSceneGraph.load(str(dsg_path))

    model.infer(G)


if __name__ == "__main__":
    main()
